---
title: "Problem Sheet 1"
output:
  word_document: default
  pdf_document: default
date: "2024-10-08"
---
# Task 1 : Hypothesis
## Import data
```{r}
setwd("/Users/carlaleone/Desktop/Exeter/Problem Sheet")
data <- read.table("BIOM4025_data_2024.csv", header=TRUE, sep = ",", 
                      stringsAsFactors = FALSE)
```

## Hypothesis:
We want to know whether morning routine affects the amount that an individual exercises. Average daily commute, wake up time, in terms of hours after midnight, and whether an individual has breakfast are not are the factors describing morning routine. 
We expect individuals to exercise more if they wake up earlier, have breakfast, and have a shorter average commute time. 


# Task 2: Model

1. Adjust columns to make them the appropriate units and classes.
```{r}
# add other columns
data$avg.commute<- (data$Commute.today + data$Commute.yesterday)/ 2 #average commute of individual
class(data$Waking.up.time) #character class, so need to convert it to numeric
data$wakeup<- as.POSIXct(paste("2024-01-01", data$Waking.up.time), format = "%Y-%m-%d %H:%M") #convert character to date and time format
data$hours.midnight<-  as.numeric(format(data$wakeup, "%H")) + as.numeric(format(data$wakeup, "%M")) / 60 #convert date and time to numeric
# are there any missing values?
is.na(data$avg.commute)
data <- data[!is.na(data$avg.commute),] #remove na from average commute column
```


2. Explore variables + Check for correlations or interactions in the predictors:
```{r}
# Plot Exercise against hours slept
mean(data$Hours.Slept)
# mean hours slept = 8.252778
plot(data$Exercise~data$Hours.Slept)
#The data seems to be centered around the mean, so I would expect the model to have a curved line and peak at the mean.Therefore, I will consider adding a square term. 
```


```{r}
# Plot Exercise against average commute
plot(data$Exercise~data$avg.commute)
# Again,no obvious relationships from the data, but could be leaning towards a positive slope.
```


```{r}
#Check if continuous variables are correlated
cor.test(data$Hours.Slept,data$avg.commute) 
#not correlated
#p = 0.5643, cor = -0.06157292 
```


```{r}
#Is there a potential relationship between the categorical and continuous predictors?
print(aggregate(data$Hours.Slept, by=list(data$Breakfast), mean, na.rm =T))
```


```{r}
# Visualize the table with a box plot
boxplot(Hours.Slept~Breakfast, data=data)
#Seems like people who eat breakfast sleep longer.
```


```{r}
hist(data$Exercise)
# The response is not normal, but it is count data so should be modeled in a poisson distribution
```

3. Create the model

- Starting with the most complex model
```{r}
msi1<- glm(Exercise~Hours.Slept+ Hours.Slept*Breakfast + I(Hours.Slept^2) + avg.commute, data=data, family= poisson)
summary(msi1)
anova(msi1, test="Chisq")
# we can remove average commute
```

- Is the interaction term significant?
First, model without interaction
```{r}
m.s<- glm(Exercise~Hours.Slept + Breakfast+ I(Hours.Slept^2), data=data, family= poisson)
# without interaction
summary(m.s)
# AIC = 374.53
# No overdispersion
```

Model with interaction
```{r}
m.s.i<- glm(Exercise~Hours.Slept+ Hours.Slept*Breakfast + I(Hours.Slept^2), data=data, family= poisson)
summary(m.s.i)
#AIC = 372.53
# No overdispersion
```

Compare the two models in an analysis of deviance:
```{r}
anova(m.s,m.s.i,test ="Chisq")
```
The more complex model, with the interaction term has a lower residual deviance and is a significantly better fit of the data p = 0.04557. It is more complex, but it is also better at modelling the data and has a lower AIC. Both models have a residual deviance below the residual degrees of freedom, meaning they are not overdispersed. 

- Checking diagnostic plots
```{r}
par(mfrow=c(2,2))
plot(m.s.i)
```
```{r}
anova(m.s.i, test="Chisq")
```

The diagnostic plots only look ok for the QQ Normal plot. The variances do not look evenly distributed, however, the diagnostic plots for glm are harder to interpret. Therefore, we will still use the more complex model as it is the best fit for the data. So this is the final model:

`glm(Exercise~Hours.Slept*Breakfast + I(Hours.Slept^2), data = data, family = poisson)`



# Task 3: Results

There was a significant quadratic relationship between the the number of times and individual exercised and hours slept (b±SE = -0.04178 ±0.01812; Z-Value 1,85 = -2.3066; P =0.0211). Note that the parameter estimate is on the log scale.

While the interaction term of Breakfast was not significant in the model prediction, it did significantly improve the model fit in an analysis of deviance (χ2 1 = 3.9976 , p = 0.04557).  


# Task 4: Plot
First create a new data fram for the predicted values to ensure a smooth line in the final plot.
```{r}
newdata.Y <- data.frame(Breakfast=rep("Yes", 100),
                     Hours.Slept=seq(min(data$Hours.Slept[data$Breakfast=="Yes"]),
                                max(data$Hours.Slept[data$Breakfast=="Yes"]),
                                                 length.out=100))

newdata.N <- data.frame(Breakfast=rep("No", 100),
                         Hours.Slept=seq(min(data$Hours.Slept[data$Breakfast=="No"]),
                                     max(data$Hours.Slept[data$Breakfast=="No"]),
                                                  length.out=100))

predicted.Y2 <- predict(m.s.i, newdata.Y, type='response')
predicted.N2 <- predict(m.s.i, newdata.N, type='response')
```

Now plot using the new data:
```{r}
plot(Exercise ~ Hours.Slept, data=data, pch=NA, xlab="Hours of Sleep", ylab="Exercise (Times per week)")
points(Exercise ~ Hours.Slept, data=data[data$Breakfast=="Yes", ], pch=19, col="blue") 
points(Exercise ~ Hours.Slept, data=data[data$Breakfast=="No", ], pch=19, col="red")
lines(predicted.Y2[order(newdata.Y$Hours.Slept)] ~
        sort(newdata.Y$Hours.Slept), lwd=1.5, col="blue")
lines(predicted.N2[order(newdata.N$Hours.Slept)] ~
        sort(newdata.N$Hours.Slept), lwd=1.5, col="red")
legend(x="topleft", legend=c("Yes", "No"), pch=19,
col=c("blue", "red"), lwd=c(1,1), title="Eats Breakfast", cex=0.8)
```

